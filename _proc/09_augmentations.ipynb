{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Because this will help\n",
    "output-file: augmentations.html\n",
    "title: Augmentations\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### create_patch\n",
       "\n",
       ">      create_patch (xb, patch_len, stride, return_patch_num=False,\n",
       ">                    constant_pad=False, constant_pad_value=0, max_seq_len=None)\n",
       "\n",
       "*xb: [bs x n_vars x seq_len]*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### create_patch\n",
       "\n",
       ">      create_patch (xb, patch_len, stride, return_patch_num=False,\n",
       ">                    constant_pad=False, constant_pad_value=0, max_seq_len=None)\n",
       "\n",
       "*xb: [bs x n_vars x seq_len]*"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(create_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1000]), torch.Size([4, 1, 505]), torch.Size([4, 2, 500]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 1000)\n",
    "\n",
    "# test seq_len > patch len == stride \n",
    "xb = create_patch(x, patch_len=505, stride=500, constant_pad=False)\n",
    "xb_rep = create_patch(x, patch_len=500, stride=500, constant_pad=True)\n",
    "x.shape, xb.shape, xb_rep.shape\n",
    "#xb_rep_short = create_patch(x_short, patch_en=502, stride=500, replication_pad=False)b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 7, 1350000]),\n",
       " torch.Size([1, 1318, 7, 1024]),\n",
       " torch.Size([1, 1319, 7, 1024]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,7,1350000)\n",
    "\n",
    "# test seq_len > patch len == stride \n",
    "xb = create_patch(x, patch_len=1024, stride=1024, constant_pad=False)\n",
    "xb_rep = create_patch(x, patch_len=1024, stride=1024, constant_pad=True)\n",
    "x.shape, xb.shape, xb_rep.shape\n",
    "#xb_rep_short = create_patch(x_short, patch_en=502, stride=500, replication_pad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### unpatch\n",
       "\n",
       ">      unpatch (x, seq_len, remove_padding=True)\n",
       "\n",
       "*x: [bs/None x patch_num x n_vars x patch_len]\n",
       "returns x: [bs x n_vars x seq_len]*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### unpatch\n",
       "\n",
       ">      unpatch (x, seq_len, remove_padding=True)\n",
       "\n",
       "*x: [bs/None x patch_num x n_vars x patch_len]\n",
       "returns x: [bs x n_vars x seq_len]*"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(unpatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 50]), torch.Size([1, 9, 1, 6]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,1,50)\n",
    "\n",
    "# test seq_len > patch len == stride \n",
    "xb = create_patch(x, patch_len=6, stride=6, constant_pad=True)\n",
    "xb = unpatch(xb, seq_len=50, remove_padding=False)\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### random_masking\n",
       "\n",
       ">      random_masking (xb, mask_ratio)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### random_masking\n",
       "\n",
       ">      random_masking (xb, mask_ratio)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(random_masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### mask_patches_simple\n",
       "\n",
       ">      mask_patches_simple (xb, mask_ratio)\n",
       "\n",
       "*Function that masks patches in a simple way\n",
       "\n",
       "xb: [bs x patch_num x n_vars x patch_len]\n",
       "padding_mask [bs x patch_num x 1|num_vars x patch_len]*\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| xb | input tensor of size 3 or 4 to be masked |\n",
       "| mask_ratio | ratio of masking of patches |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### mask_patches_simple\n",
       "\n",
       ">      mask_patches_simple (xb, mask_ratio)\n",
       "\n",
       "*Function that masks patches in a simple way\n",
       "\n",
       "xb: [bs x patch_num x n_vars x patch_len]\n",
       "padding_mask [bs x patch_num x 1|num_vars x patch_len]*\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| xb | input tensor of size 3 or 4 to be masked |\n",
       "| mask_ratio | ratio of masking of patches |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(mask_patches_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(50,16,7,50)\n",
    "mask_ratio = 0.4\n",
    "\n",
    "x_new, mask = mask_patches_simple(x,mask_ratio=mask_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### jitter_augmentation\n",
       "\n",
       ">      jitter_augmentation (x, mask_ratio=0.05, jitter_ratio=0.05)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### jitter_augmentation\n",
       "\n",
       ">      jitter_augmentation (x, mask_ratio=0.05, jitter_ratio=0.05)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(jitter_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### remove_values\n",
       "\n",
       ">      remove_values (x, mask_ratio)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### remove_values\n",
       "\n",
       ">      remove_values (x, mask_ratio)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(remove_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## note that the random number generator advances state...\n",
    "torch.manual_seed(42)\n",
    "x = torch.randn(4,7,1000)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "x_new, n_masks = jitter_augmentation(x)\n",
    "n_masks /(4* 7*1000)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "x_new2, n_masks2 = jitter_augmentation(x)\n",
    "torch.equal(x_new, x_new2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### shuffle_dim\n",
       "\n",
       ">      shuffle_dim (x, dim=1, p=0.5)\n",
       "\n",
       "*shuffles a dimension randomly along dim\n",
       "x: [bs x n channels x n patches x patch len]*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### shuffle_dim\n",
       "\n",
       ">      shuffle_dim (x, dim=1, p=0.5)\n",
       "\n",
       "*shuffles a dimension randomly along dim\n",
       "x: [bs x n channels x n patches x patch len]*"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(shuffle_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### reverse_sequence\n",
       "\n",
       ">      reverse_sequence (x, seq_dim=(-1,), p=0.5)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### reverse_sequence\n",
       "\n",
       ">      reverse_sequence (x, seq_dim=(-1,), p=0.5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(reverse_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4,1,5,5).to('cuda')\n",
    "\n",
    "torch.equal(shuffle_dim(x), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### IntraClassCutMix1d\n",
       "\n",
       ">      IntraClassCutMix1d (mix_prob=0.5, return_y_every_sec=30, frequency=125,\n",
       ">                          return_sequence_padding_mask=True)\n",
       "\n",
       "*Intra-class CutMix for 1D data (e.g., time-series). \n",
       "\n",
       "This is a callback that can be used to apply CutMix to the training data.\n",
       "It is used to mix segments within the same class.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| mix_prob | float | 0.5 | probability of applying cutmix |\n",
       "| return_y_every_sec | int | 30 | length of segment to mix, if one value of y corresponds to 30 seconds of signal data, this should be set to 30. |\n",
       "| frequency | int | 125 | frequency of the data |\n",
       "| return_sequence_padding_mask | bool | True | whether to return the sequence padding mask |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### IntraClassCutMix1d\n",
       "\n",
       ">      IntraClassCutMix1d (mix_prob=0.5, return_y_every_sec=30, frequency=125,\n",
       ">                          return_sequence_padding_mask=True)\n",
       "\n",
       "*Intra-class CutMix for 1D data (e.g., time-series). \n",
       "\n",
       "This is a callback that can be used to apply CutMix to the training data.\n",
       "It is used to mix segments within the same class.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| mix_prob | float | 0.5 | probability of applying cutmix |\n",
       "| return_y_every_sec | int | 30 | length of segment to mix, if one value of y corresponds to 30 seconds of signal data, this should be set to 30. |\n",
       "| frequency | int | 125 | frequency of the data |\n",
       "| return_sequence_padding_mask | bool | True | whether to return the sequence padding mask |"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(IntraClassCutMix1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4,7,90)\n",
    "x_c = x.clone()\n",
    "y = torch.randint(0, 5, size=(4,90//30))\n",
    "xxt = IntraClassCutMix1d(mix_prob=1, frequency=1, return_y_every_sec=30, return_sequence_padding_mask=False)\n",
    "batch = (x,y)\n",
    "xxt.on_train_batch_start(None, None, batch, 0)\n",
    "torch.equal(x_c, batch[0]) == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### IntraClassCutMixBatch\n",
       "\n",
       ">      IntraClassCutMixBatch (mix_prob=0.5, return_y_every_sec=30,\n",
       ">                             frequency=125, return_sequence_padding_mask=True,\n",
       ">                             intra_class_only=True)\n",
       "\n",
       "*Intra-class CutMix for 1D data (e.g., time-series). \n",
       "\n",
       "This is a callback that can be used to apply CutMix to the training data.\n",
       "It is used to mix segments within the same class.\n",
       "\n",
       "This is different to IntraClassCutMix1d in that it mixes segments of the same class across batches of data, rather than just at the same segment*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| mix_prob | float | 0.5 | probability of applying cutmix |\n",
       "| return_y_every_sec | int | 30 | length of segment to mix, if one value of y corresponds to 30 seconds of signal data, this should be set to 30. |\n",
       "| frequency | int | 125 | frequency of the data |\n",
       "| return_sequence_padding_mask | bool | True | whether to return the sequence padding mask |\n",
       "| intra_class_only | bool | True | whether to mix only within same class (True) or across all classes (False) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### IntraClassCutMixBatch\n",
       "\n",
       ">      IntraClassCutMixBatch (mix_prob=0.5, return_y_every_sec=30,\n",
       ">                             frequency=125, return_sequence_padding_mask=True,\n",
       ">                             intra_class_only=True)\n",
       "\n",
       "*Intra-class CutMix for 1D data (e.g., time-series). \n",
       "\n",
       "This is a callback that can be used to apply CutMix to the training data.\n",
       "It is used to mix segments within the same class.\n",
       "\n",
       "This is different to IntraClassCutMix1d in that it mixes segments of the same class across batches of data, rather than just at the same segment*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| mix_prob | float | 0.5 | probability of applying cutmix |\n",
       "| return_y_every_sec | int | 30 | length of segment to mix, if one value of y corresponds to 30 seconds of signal data, this should be set to 30. |\n",
       "| frequency | int | 125 | frequency of the data |\n",
       "| return_sequence_padding_mask | bool | True | whether to return the sequence padding mask |\n",
       "| intra_class_only | bool | True | whether to mix only within same class (True) or across all classes (False) |"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(IntraClassCutMixBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intra-class CutMixBatch is being applied!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4,7,90)\n",
    "x_c = x.clone()\n",
    "y = torch.randint(0, 5, size=(4,90//30))\n",
    "xxt = IntraClassCutMixBatch(mix_prob=1, frequency=1, return_y_every_sec=30, return_sequence_padding_mask=False)\n",
    "batch = (x,y)\n",
    "batch = xxt.on_train_batch_start(None, None, batch, 0)\n",
    "torch.equal(x_c, batch[0]) == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### MixupCallback\n",
       "\n",
       ">      MixupCallback (num_classes, mixup_alpha=0.4,\n",
       ">                     return_sequence_padding_mask=True, ignore_index=-100)\n",
       "\n",
       "*Mixup for 1D data (e.g., time-series).\n",
       "\n",
       "This callback applies Mixup to the training data, blending both the input data and the labels.\n",
       "\n",
       "See tsai implementation here: https://github.com/timeseriesAI/tsai/blob/bdff96cc8c4c8ea55bc20d7cffd6a72e402f4cb2/tsai/data/mixed_augmentation.py#L43\n",
       "\n",
       "Note that this creates non-integer labels/soft labels. Loss functions should be able to handle this.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| num_classes |  |  |  |\n",
       "| mixup_alpha | float | 0.4 | alpha parameter for the beta distribution |\n",
       "| return_sequence_padding_mask | bool | True | whether to return the sequence padding mask |\n",
       "| ignore_index | int | -100 | ignore index |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### MixupCallback\n",
       "\n",
       ">      MixupCallback (num_classes, mixup_alpha=0.4,\n",
       ">                     return_sequence_padding_mask=True, ignore_index=-100)\n",
       "\n",
       "*Mixup for 1D data (e.g., time-series).\n",
       "\n",
       "This callback applies Mixup to the training data, blending both the input data and the labels.\n",
       "\n",
       "See tsai implementation here: https://github.com/timeseriesAI/tsai/blob/bdff96cc8c4c8ea55bc20d7cffd6a72e402f4cb2/tsai/data/mixed_augmentation.py#L43\n",
       "\n",
       "Note that this creates non-integer labels/soft labels. Loss functions should be able to handle this.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| num_classes |  |  |  |\n",
       "| mixup_alpha | float | 0.4 | alpha parameter for the beta distribution |\n",
       "| return_sequence_padding_mask | bool | True | whether to return the sequence padding mask |\n",
       "| ignore_index | int | -100 | ignore index |"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MixupCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixup is being applied!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4,7,90)\n",
    "x_c = x.clone()\n",
    "y_og = torch.randint(0, 5, size=(4,90//30))\n",
    "y_og[1,2] = -100\n",
    "y_og[2,1] = -100\n",
    "y_c = y_og.clone()\n",
    "xxt = MixupCallback(num_classes=5, mixup_alpha=0.4, return_sequence_padding_mask=False)\n",
    "batch = (x,y_og)\n",
    "batch = xxt.on_train_batch_start(None, None, batch, 0)\n",
    "torch.equal(x_c, batch[0]) == False, torch.equal(y_c, batch[1]) == False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
