{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slumber\n",
    "\n",
    "> I'm tired too. Here are some things that might help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp slumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pyedflib, edfio, torch, zarr, warnings, datetime as dt, torch.nn.functional as F, dask.array as da, numpy as np, pandas as pd, plotly.graph_objects as go, plotly.express as px\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.signal import resample\n",
    "import torchaudio.functional as F_audio\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from plotly_resampler import FigureWidgetResampler\n",
    "from mne.io import read_raw_edf\n",
    "\n",
    "from pftsleep.data_preprocessing import calculate_samples_mp, calculate_stats_all, interpolate_nan_clip\n",
    "from pftsleep.signal import butterworth\n",
    "from scipy.ndimage import median_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "ALL_FREQUENCY_FILTERS = {'ECG':[0.5,40], \n",
    "            'ECG (LL-RA)':[0.5,40],\n",
    "            'EKG':[0.5,40],\n",
    "            'ECG (L-R)':[0.5,40],\n",
    "            'EOG(L)':[0.3,30],\n",
    "            'EOG-L':[0.3,30],\n",
    "            'E1':[0.3,30],\n",
    "            'LOC':[0.3,30], \n",
    "            'E1-M2':[0.3,30], \n",
    "            'E1-AVG':[0.3,30],\n",
    "            'EMG':[0.3,30],\n",
    "            'cchin_l':[0.3,30],\n",
    "            'chin':[0.3,30],\n",
    "            'EMG (L-R)': [0.3,30], \n",
    "            'EMG (1-2)': [0.3,30],\n",
    "            'EMG (1-3)': [0.3,30], \n",
    "            'Chin3':[0.3,30],\n",
    "            'C4-M1':[0.3,30],\n",
    "            'C4_M1':[0.3,30],\n",
    "            'EEG':[0.3,30],\n",
    "            \"EEG(sec)\":[0.3,30],\n",
    "            \"EEG1\":[0.3,30],\n",
    "            \"EEG2\":[0.3,30],\n",
    "            'EEG3':[0.3,30],\n",
    "            'C3-M2':[0.3,30],\n",
    "            'C3_M2':[0.3,30],\n",
    "            'C4-AVG':[0.3,30],\n",
    "            'SaO2':[0.4, None],\n",
    "            'SpO2':[0.4, None],\n",
    "            'spo2':[0.4, None],\n",
    "            'THOR RES':[0.5, None],\n",
    "            'Thor':[0.5, None],\n",
    "            'thorax':[0.5, None],\n",
    "            'Thoracic':[0.5, None],\n",
    "            'Chest':[0.5, None],\n",
    "            'ABDO RES':[0.5, None],\n",
    "            'abdomen':[0.5, None],\n",
    "            'Abdo':[0.5, None],\n",
    "            'Abdominal':[0.5, None],\n",
    "            'ABD':[0.5, None]\n",
    "            }\n",
    "\n",
    "VOLTAGE_CHANNELS = ['ECG', 'ECG (LL-RA)', 'EKG', 'ECG (L-R)', 'EOG(L)', 'EOG-L', 'E1', 'LOC', 'E1-M2', 'E1-AVG','EMG', 'cchin_l', 'chin', 'EMG (L-R)', 'EMG (1-2)', 'EMG (1-3)', 'Chin3', 'C4-M1', 'C4_M1', 'EEG', 'EEG1', 'EEG2', 'EEG3', 'C3-M2', 'C3_M2', 'C4-AVG']\n",
    "\n",
    "# physiological possible ranges to clip/interpolate\n",
    "CLIP_INTERPOLATE_RANGES = {'SaO2': {\"phys_range\":[50,100], \"percentiles\":None}, 'SpO2':{\"phys_range\":[50,100], \"percentiles\":None}}\n",
    "\n",
    "# wsc channels for training, note it does not have C4_M1\n",
    "WSC_CHANNELS = [['ECG'], ['E1'], ['cchin_l', 'chin'], ['C3_M2'], ['spo2'], ['thorax'], ['abdomen']]\n",
    "\n",
    "# apples channels for training, double checked and in the APPLES paper, LOC is referenced with M2\n",
    "## see: https://academic.oup.com/sleep/article/34/3/303/2433804 and https://gitlab-scm.partners.org/zzz-public/nsrr/-/tree/master/studies/apples\n",
    "APPLES_CHANNELS = [[\"ECG\"], [\"LOC\"], [\"EMG\"], [\"C4_M1\", \"C3_M2\"], [\"SpO2\"], [\"thorax\"], [\"abdomen\"]]\n",
    "\n",
    "# mesa channels for training, note that it does not have C3_M2, EEG3 == C4_M1\n",
    "## note also that mesa refereences E1-fpz! not E!-M@\n",
    "MESA_CHANNELS = [[\"EKG\"], [\"EOG-L\"], [\"EMG\"], [\"EEG3\"], [\"SpO2\"], [\"Thor\"], [\"Abdo\"]]\n",
    "\n",
    "# shhs channels for training \n",
    "## note that EOG(L) is referenced with PG1 (ground)\n",
    "## EEG is C4_M1 and EEG(sec) is C3_M2\n",
    "SHHS_CHANNELS = [[\"ECG\"], [\"EOG(L)\"], [\"EMG\"], [\"EEG\", \"EEG(sec)\"], [\"SaO2\"], [\"THOR RES\"], [\"ABDO RES\"]]\n",
    "\n",
    "# most of these weere derived in the zarr job file\n",
    "MROS_CHANNELS = [['ECG (L-R)'], ['E1-M2'], ['EMG (L-R)'], [\"C4-M1\", \"C3-M2\"], ['SaO2', 'SpO2'], ['Thoracic', 'Chest'], ['Abdominal', 'ABD']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDF Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read EDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_edf(file_path, # file path of edf\n",
    "             channels=None, # channels in edf to read, will raise warning if channels do not exist\n",
    "             frequency=None # frequency to resample all signals to\n",
    "             )->Union[list, dict]: # tuple of signals and header dictionary\n",
    "    \"\"\"\n",
    "    Function to read an edf file and return a list of signals and header with the option to resample to a passed frequency\n",
    "    \"\"\"\n",
    "    pyedflib.close_file(0) # ensure files are closed \n",
    "    with pyedflib.EdfReader(file_path) as f:\n",
    "        num_channels = f.signals_in_file\n",
    "        if channels is not None:\n",
    "            available_channels = [channel.upper() for channel in f.getSignalLabels()]\n",
    "            channels = [channel.upper() for channel in channels]\n",
    "            if len(set(channels) - set(available_channels)) != 0:\n",
    "                warnings.warn(f'Missing channels {set(channels) - set(available_channels)}')\n",
    "            channels_to_get = list(set(channels) & set(available_channels))\n",
    "            channels_idxs = [available_channels.index(c) for c in channels_to_get]\n",
    "        else:\n",
    "            channels_idxs = range(num_channels)\n",
    "        header = f.getHeader()\n",
    "        header['Duration'] = f.getFileDuration()\n",
    "        header['SignalHeaders'] = [f.getSignalHeaders()[c] for c in channels_idxs]\n",
    "        signals = []\n",
    "        if frequency is not None:\n",
    "            required_length = header['Duration'] * frequency\n",
    "        for c in channels_idxs:\n",
    "            signal = f.readSignal(c, digital=False)\n",
    "            if frequency is not None and len(signal) != required_length:\n",
    "                signal = resample(signal, required_length)\n",
    "                header['SignalHeaders'][c]['sample_rate'] = frequency\n",
    "                header['SignalHeaders'][c]['sample_frequency'] = frequency\n",
    "            signals.append(signal)\n",
    "    return signals, header\n",
    "    \n",
    "    #full_range = pd.date_range(header['startdate'], periods=header['Duration'], freq='1S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_edf_mne(file_path, # file path of edf\n",
    "             channels=None, # channels in edf to read, will raise warning if channels do not exist\n",
    "             frequency=None # frequency to resample all signals to\n",
    "             )->Union[list, dict]: # tuple of signals and header dictionary\n",
    "    \"\"\"\n",
    "    function to read edf with mne library\n",
    "    i dont recommend using this. Use edfio instead.\n",
    "    \"\"\"\n",
    "    raw_edf = read_raw_edf(file_path)\n",
    "    signal_labels = raw_edf.ch_names\n",
    "    num_channels = len(signal_labels)\n",
    "    if channels is not None:\n",
    "        available_channels = [channel.upper() for channel in signal_labels]\n",
    "        channels = [channel.upper() for channel in channels]\n",
    "        if len(set(channels) - set(available_channels)) != 0:\n",
    "            warnings.warn(f'Missing channels {set(channels) - set(available_channels)}')\n",
    "        channels_to_get = list(set(channels) & set(available_channels))\n",
    "        channels_idxs = [available_channels.index(c) for c in channels_to_get]\n",
    "    else:\n",
    "        channels_idxs = range(num_channels)\n",
    "    info_dict = dict(raw_edf.info)\n",
    "    header = {'technician': info_dict.get('experimenter'),\n",
    "        'recording_additional': '',\n",
    "        'patientname': info_dict.get('subject_info').get('last_name'),\n",
    "        'patient_additional': '',\n",
    "        'patientcode': '',\n",
    "        'equipment': '',\n",
    "        'admincode': '',\n",
    "        'sex': 'Female' if info_dict.get('subject_info').get('sex') == 0 else 'Male',\n",
    "        'startdate': info_dict.get('meas_date'),\n",
    "        'birthdate': info_dict.get('subject_info').get('birthday'),\n",
    "        'gender': 'Female' if info_dict.get('subject_info').get('sex') == 0 else 'Male',\n",
    "        'Duration':int(len(raw_edf) / info_dict.get('sfreq')),\n",
    "        'SignalHeaders':[{'label':i['ch_name'], 'sample_frequency':info_dict.get('sfreq'), 'sample_rate':info_dict.get('sfreq')} for i in info_dict.get('chs')]\n",
    "    }\n",
    "    signals = []\n",
    "    if frequency is not None:\n",
    "        required_length = header['Duration'] * frequency\n",
    "    for c in channels_idxs:\n",
    "        signal = raw_edf[c][0][0]\n",
    "        if frequency is not None and len(signal) != required_length:\n",
    "            signal = resample(signal, required_length)\n",
    "        signals.append(signal)\n",
    "    return signals, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_edf_edfio(file_path, # file path of edf\n",
    "             channels=None, # channels in edf to read, will raise warning if channels do not exist\n",
    "             frequency=None # frequency to resample all signals to\n",
    "             )->Union[list, dict]: # tuple of signals and header dictionary\n",
    "    \"\"\"\n",
    "    function to read edfs with edfio\n",
    "    \"\"\"\n",
    "    f = edfio.read_edf(file_path, lazy_load_data=True)\n",
    "    num_channels = f.num_signals\n",
    "    if channels is not None:\n",
    "        available_channels = [channel.upper() for channel in f.labels]\n",
    "        channels = [channel.upper() for channel in channels]\n",
    "        if len(set(channels) - set(available_channels)) != 0:\n",
    "            warnings.warn(f'Missing channels {set(channels) - set(available_channels)}')\n",
    "        channels_to_get = list(set(channels) & set(available_channels))\n",
    "        channels_idxs = [available_channels.index(c) for c in channels_to_get]\n",
    "    else:\n",
    "        channels_idxs = range(num_channels)\n",
    "    header = {'technician': '' if f.recording.get_subfield(2) == 'X' else f.recording.get_subfield(2),\n",
    "            'recording_additional': '',\n",
    "            'patientname': '' if f.patient.get_subfield(3) == 'X' else f.patient.get_subfield(3),\n",
    "            'patient_additional': '',\n",
    "            'patientcode': '',\n",
    "            'equipment': '',\n",
    "            'admincode': '',\n",
    "            'sex': '' if f.patient.get_subfield(1) == 'X' else f.patient.get_subfield(1).replace('M', 'Male').replace('F', 'Female'),\n",
    "            'startdate': dt.datetime.combine(f.startdate, f.starttime),\n",
    "            'birthdate': f.patient.get_subfield(2).lower().replace('-',' ') if f.patient.get_subfield(2) != 'X' else '',\n",
    "            'gender': '' if f.patient.get_subfield(1) == 'X' else f.patient.get_subfield(1).replace('M', 'Male').replace('F', 'Female'),\n",
    "            'Duration': int(f.duration),\n",
    "            'SignalHeaders':[{'label':f.signals[i].label, \n",
    "                            'dimension':f.signals[i].physical_dimension,\n",
    "                            'sample_rate':f.signals[i].sampling_frequency,\n",
    "                            'sample_frequency':f.signals[i].sampling_frequency,\n",
    "                            'physical_max': f.signals[i].physical_max,\n",
    "                            'physical_min': f.signals[i].physical_min,\n",
    "                            'digital_max': f.signals[i].digital_max,\n",
    "                            'digital_min': f.signals[i].digital_min,\n",
    "                            'prefilter': f.signals[i].prefiltering,\n",
    "                            'transducer': f.signals[i].transducer_type\n",
    "                            } for i in channels_idxs]\n",
    "    }\n",
    "    signals = []\n",
    "    if frequency is not None:\n",
    "        required_length = header['Duration'] * frequency\n",
    "    for c in channels_idxs:\n",
    "        signal = f.signals[c].data\n",
    "        if frequency is not None and len(signal) != required_length:\n",
    "            signal = resample(signal, required_length)\n",
    "            header['SignalHeaders'][c]['sample_rate'] = frequency\n",
    "            header['SignalHeaders'][c]['sample_frequency'] = frequency\n",
    "        signals.append(signal)\n",
    "    return signals, header\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Hypnograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_hypnogram(file, # file path of the hypnogram csv\n",
    "                   epoch_length = None # epoch length of the hypnogram measurements, if passed will repeat this many times at each element\n",
    "                   )->np.array: # numpy array of hypnogram\n",
    "     \"\"\"\n",
    "     Function that reads a hypnogram csv and returns a numpy array of the hypnogram with optional repeats\n",
    "     \"\"\"\n",
    "     y = pd.read_csv(file, header=None, names=[1])[1].to_numpy()\n",
    "     if epoch_length is not None:\n",
    "         y = y.repeat(epoch_length)\n",
    "     return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDFs to Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def edf_signals_to_zarr(edf_file_path, write_data_dir, overwrite=False, channels=None, channel_name_map=None, frequency=None, hyp_epoch_length=30, hyp_data_dir=None):\n",
    "    \"\"\"\n",
    "    Function that converts an edf to a zarr file\n",
    "\n",
    "    try_mne: tries to load files with mne instead of pyedflib (if there is an error). This seems dangerous as mne converts units (and potentially resamples, while pyedflib does not)\n",
    "    \"\"\"\n",
    "    if channel_name_map is None:\n",
    "        channel_name_map = {}\n",
    "    edf_file_path = Path(edf_file_path)\n",
    "    try:\n",
    "        signals, header = read_edf(str(edf_file_path), channels=channels, frequency=frequency)\n",
    "    except Exception as e:\n",
    "        # try with edfio library, mne library is meh, because mne resamples data to highest frequency\n",
    "        # then it adjusts units. edfio and pyedflib do not do this.\n",
    "        signals, header = read_edf_edfio(str(edf_file_path), channels=channels, frequency=frequency)\n",
    "    store = zarr.DirectoryStore(str(Path(write_data_dir)/edf_file_path.stem) + '.zarr')\n",
    "    if overwrite:\n",
    "        root_grp = zarr.group(store, overwrite=True)\n",
    "    else:\n",
    "        # this should not replace data, so we can continue to append to this group.\n",
    "        root_grp = zarr.group(store, overwrite=False)\n",
    "    signal_headers = header.pop('SignalHeaders')\n",
    "    root_grp.attrs['header'] = {k:str(v) for k,v in header.items()}\n",
    "    # get y/sleep staging data\n",
    "    try:\n",
    "        # try to get hypnogram data if it exists\n",
    "        if hyp_data_dir is not None:\n",
    "            hyp_data_dir = Path(hyp_data_dir)\n",
    "            hyp_file_path = hyp_data_dir/Path(edf_file_path.stem + \"-hyp.csv\")\n",
    "        else:\n",
    "            hyp_file_path = edf_file_path.parent/Path(edf_file_path.stem + \"-hyp.csv\") # [V] V is variable per file and does not necessarily == patch_num\n",
    "        \n",
    "        if frequency is not None:\n",
    "            y = read_hypnogram(hyp_file_path, epoch_length=(hyp_epoch_length*frequency))\n",
    "        else:\n",
    "            y = read_hypnogram(hyp_file_path, epoch_length=(hyp_epoch_length))\n",
    "\n",
    "        if frequency is not None and len(y) < len(signals[-1]):\n",
    "            # hypnogram is shorter, trim signals\n",
    "            signals = signals[:, :len(y)] # [n_vars x T]\n",
    "        elif frequency is not None and len(y) > len(signals[-1]):\n",
    "            # signals are longer, trim hypnogram\n",
    "            y = y[:len(signals[-1])] # [T]\n",
    "    except:\n",
    "        y = None\n",
    "        pass\n",
    "    # write signals\n",
    "    for i, h in zip(signals, signal_headers):\n",
    "        a = da.from_array(np.array(i, dtype=np.float16), chunks='auto') # read using dask\n",
    "        name = h['label'] if h['label'] not in channel_name_map else channel_name_map[h['label']]\n",
    "        h['mapped_label'] = name\n",
    "        a.to_zarr(url=store, component=name, compute=True) # convert to zarr format\n",
    "        root_grp[name].attrs['signal_header'] = h # assign metadata\n",
    "\n",
    "    # write hypnogram\n",
    "    if y is not None:\n",
    "        a = da.from_array(y, chunks='auto')\n",
    "        a.to_zarr(url=store, component='hypnogram', compute=True)\n",
    "    zarr.consolidate_metadata(store)\n",
    "    return root_grp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Supervised Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def trim_wake_epochs_from_hypnogram(hypnogram, padding_mask=-100):\n",
    "    \"\"\"\n",
    "    Function to trim wake epochs (if wake is the largest class) from hypnograms\n",
    "    This function trims the wake epochs from the beginning and/or end of the hypnogram\n",
    "\n",
    "    Adapted from Phan et al L-SeqSleepNet\n",
    "    \"\"\"\n",
    "    # Check if Wake (stage 0) is the largest class\n",
    "    idx, counts = hypnogram.unique(return_counts=True)\n",
    "    counts = counts.numpy()\n",
    "    if 0 not in idx:\n",
    "        return hypnogram\n",
    "    wake_idx = torch.where(idx==0)[0][0].item()\n",
    "    n_wakes = counts[wake_idx].item()\n",
    "    hypnogram = hypnogram.numpy()\n",
    "    if n_wakes > np.max(counts[wake_idx+1:]):\n",
    "        second_largest = np.max(counts[wake_idx+1:])\n",
    "        \n",
    "        # Create boolean array for Wake indices (True where stages == 0)\n",
    "        W_ind = (hypnogram == 0)\n",
    "        \n",
    "        # Find first transition from/to Wake\n",
    "        transitions = np.diff(W_ind.astype(int))\n",
    "        last_evening_W_index = np.where(transitions != 0)[0][0]\n",
    "        \n",
    "        # Calculate number of evening Wake epochs\n",
    "        num_evening_W = last_evening_W_index + 1 if hypnogram[0] == 0 else 0\n",
    "        \n",
    "        # Find last transition from/to Wake\n",
    "        first_morning_W_index = np.where(transitions != 0)[0][-1] + 1\n",
    "        num_morning_W = len(hypnogram) - first_morning_W_index\n",
    "        \n",
    "        nb_pre_post_sleep_wake_eps = num_evening_W + num_morning_W\n",
    "        \n",
    "        if nb_pre_post_sleep_wake_eps > second_largest:\n",
    "            total_W_to_remove = nb_pre_post_sleep_wake_eps - second_largest\n",
    "            \n",
    "            if num_evening_W >= total_W_to_remove:\n",
    "                # Remove from beginning only\n",
    "                hypnogram[:total_W_to_remove] = padding_mask\n",
    "            else:\n",
    "                # Remove from both ends\n",
    "                evening_W_to_remove = num_evening_W\n",
    "                morning_W_to_remove = total_W_to_remove - evening_W_to_remove\n",
    "                hypnogram[:evening_W_to_remove] = padding_mask\n",
    "                hypnogram[-morning_W_to_remove:] = padding_mask\n",
    "\n",
    "    return torch.from_numpy(hypnogram)\n",
    "\n",
    "\n",
    "def trim_wake_epochs_from_signals(X, hypnogram, sequence_padding_mask, resampled_hypnogram_length, mask_x_with_zeros=False, padding_mask=-100):\n",
    "    \"\"\"\n",
    "    Function to trim wake epochs (if wake is the largest class) from signals\n",
    "\n",
    "    X: bs, channels, seq_len\n",
    "    hypnogram: bs, seq_len / resampled_hypnogram_length\n",
    "    sequence_padding_mask: bs, seq_len\n",
    "    \"\"\"\n",
    "    # find invalid exact timepoints\n",
    "    invalid_segments = hypnogram.repeat_interleave(resampled_hypnogram_length) == padding_mask\n",
    "    if mask_x_with_zeros:\n",
    "        X[:, invalid_segments] = 0\n",
    "    sequence_padding_mask[:, invalid_segments] = 1\n",
    "    return X, sequence_padding_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SelfSupervisedTimeFrequencyDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 zarr_files, # zarr files that include samples\n",
    "                 channels, # channels to use\n",
    "                 max_seq_len_sec, # maximum sequence length (in seconds) to use (this is especially relevant when you are returning both stft and raw ts data to keep them in sync)\n",
    "                 sample_seq_len_sec, # if no sample_df, generate sequences of this length in seconds as one sample\n",
    "                 sample_stride_sec, #  if no sample_df, seconds of overlap for samples from the same array, if seq_len_seconds == overlap_seconds, there is no overlap\n",
    "                 start_offset_sec=0, # number of seconds to exclude from beginning of sleep studies\n",
    "                 trim_wake_epochs=True, # indicator to trim wake epochs from hypnograms, if it is the largest class\n",
    "                 include_partial_samples=True, # indicator to include data from partial samples when return_full_length is false\n",
    "                 sample_df=None, # dataframe indicating which indices within each zarr file includes a sample\n",
    "                 frequency=125, # frequency of underlying data\n",
    "                 return_hypnogram_every_sec=30, # integer value indicating the step in indexing in seconds\n",
    "                 hypnogram_padding_mask=-100, # padded value to add to target and indice to ignore when computing loss\n",
    "                 hypnogram_frequency=125, # frequency of underlying y hypnogram data\n",
    "                 butterworth_filters=None, # dictionary of low pass, high pass, and bandpass dictionary to perform on channels\n",
    "                 median_filter_kernel_size=None, # if not none, will apply median filter with kernel size\n",
    "                 voltage_channels=VOLTAGE_CHANNELS, # if not None, these channels units will be looked at and changed to microvolts from mv uv etc.\n",
    "                 clip_interpolations=None, # dictionary of channels:{'phys_range':..., 'percentiles':...} for filtering and interpolation of filtered values\n",
    "                 scale_channels=False, # indicator to scale channels to the mean and std of the zarr files. \n",
    "                 time_channel_scales=None, # dictionary of channel:mean and channel:std values for scaling. Should use training statistics \n",
    "                 return_sequence_padding_mask=False, # indicator to return the key padding mask for attention masking\n",
    "                 ):\n",
    "        self.max_seq_len = max_seq_len_sec*frequency\n",
    "        self.max_seq_len_sec = max_seq_len_sec\n",
    "        self.include_partial_samples = include_partial_samples\n",
    "        self.zarr_files = zarr_files\n",
    "        self.channels = channels\n",
    "        self.channels_has_dim = any(isinstance(i, list) for i in self.channels)\n",
    "        self.sample_seq_len_sec = sample_seq_len_sec\n",
    "        self.sample_seq_len = sample_seq_len_sec * frequency\n",
    "        self.frequency = frequency\n",
    "        self.sample_stride_sec = sample_stride_sec\n",
    "        self.scale_channels = scale_channels\n",
    "        self.clip_interpolations = clip_interpolations\n",
    "        self.return_hypnogram_every_sec = return_hypnogram_every_sec\n",
    "        self.hypnogram_padding_mask = hypnogram_padding_mask\n",
    "        self.hypnogram_frequency = hypnogram_frequency\n",
    "        self.return_sequence_padding_mask = return_sequence_padding_mask\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.trim_wake_epochs = trim_wake_epochs\n",
    "\n",
    "        self.butterworth_filters = butterworth_filters\n",
    "        self.median_filter_kernel_size = median_filter_kernel_size\n",
    "        self.voltage_channels = voltage_channels\n",
    "        \n",
    "        if sample_df is None:\n",
    "            print(f\"Calculating samples with {sample_seq_len_sec} sec length and {sample_stride_sec} sec stride with {max_seq_len_sec} sec max\")\n",
    "            self.sample_df, self.total_samples = calculate_samples_mp(zarr_files, channels=channels, max_seq_len_sec=max_seq_len_sec, sample_seq_len_sec=sample_seq_len_sec, frequency=frequency, start_offset_sec=start_offset_sec, stride_sec=sample_stride_sec, include_partial_samples=include_partial_samples)\n",
    "        else:\n",
    "            assert 'file' in sample_df, \"The `sample_df` must have a column `file` with the zarr file path.\"\n",
    "            missing_in_zarrs = len(set(sample_df['file']) - set(zarr_files))\n",
    "            missing_in_df = len(set(zarr_files) - set(sample_df['file']))\n",
    "            if missing_in_zarrs > 0 or missing_in_df > 0:\n",
    "                warnings.warn(f\"There are {missing_in_zarrs} `zarr_files` not in the `sample_df` and {missing_in_df} files in the `sample_df` that arent in the `zarr_files`, they will be ignored.\")\n",
    "            sample_df = sample_df.loc[sample_df['file'].isin(zarr_files)].copy().reset_index(drop=True)\n",
    "            self.sample_df = sample_df\n",
    "            self.total_samples = len(sample_df)\n",
    "        \n",
    "        if self.scale_channels:\n",
    "            if time_channel_scales is None or time_channel_scales == {}:\n",
    "                print(f\"Calculating sample statistics for {channels}\")\n",
    "                channel_scales_df = calculate_stats_all(zarr_files=self.sample_df.file.tolist(), channels=channels, sample_wise=False, channel_magnitude_multiple=None)\n",
    "                self.time_channel_scales = channel_scales_df.to_dict(orient='index')\n",
    "            else:\n",
    "                self.time_channel_scales = time_channel_scales\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get full length x, idx can be a slice\n",
    "        sample = self.sample_df.iloc[idx]\n",
    "        root_grp = zarr.open(sample['file'])\n",
    "        duration_seconds = int(root_grp.attrs.asdict()['header']['Duration'])\n",
    "        signals = []\n",
    "        channels = []\n",
    "        if self.channels_has_dim:\n",
    "            avail_channels = list(root_grp.array_keys())\n",
    "            for p in self.channels:\n",
    "                channels.append(next(x for x in p if x in avail_channels))\n",
    "        else:\n",
    "            channels = self.channels\n",
    "        for channel in channels:\n",
    "            channel_frequency = root_grp[channel].attrs.asdict()['signal_header']['sample_frequency']\n",
    "            channel_dimension = root_grp[channel].attrs.asdict()['signal_header']['dimension'] # whether in mV, microv or v\n",
    "            if channel_frequency != self.frequency:\n",
    "                start_idx, end_idx = int(sample['start_idx'] / self.frequency * channel_frequency), int(sample['end_idx'] / self.frequency * channel_frequency)\n",
    "            else:\n",
    "                start_idx, end_idx = sample['start_idx'], sample['end_idx']\n",
    "            temp = np.array(root_grp[channel][start_idx:end_idx], dtype=np.float32)\n",
    "            if channel_frequency < self.frequency:\n",
    "                # need to upsample first, then apply filters\n",
    "                #temp = resample(root_grp[channel][start_idx:end_idx], self.frequency*self.sample_seq_len_sec) if duration_seconds >= self.sample_seq_len_sec else resample(root_grp[channel][start_idx:end_idx], duration_seconds*self.frequency)\n",
    "                temp = F_audio.resample(torch.from_numpy(temp), channel_frequency, self.frequency).numpy()\n",
    "                if self.median_filter_kernel_size is not None:\n",
    "                    temp = median_filter(temp, size=self.median_filter_kernel_size, mode='nearest')\n",
    "                if self.butterworth_filters is not None and channel in self.butterworth_filters:\n",
    "                    freq_range = self.butterworth_filters[channel]\n",
    "                    btype = 'highpass' if freq_range[0] is None else 'lowpass' if freq_range[1] is None else 'bandpass'\n",
    "                    freq_range = freq_range[1] if freq_range[0] is None else freq_range[0] if freq_range[1] is None else freq_range\n",
    "                    temp = butterworth(temp, freq_range=freq_range, btype=btype, fs=self.frequency, order=2)\n",
    "            elif channel_frequency > self.frequency:\n",
    "                # need to upsample or downsample, filter first, then resample\n",
    "                if self.median_filter_kernel_size is not None:\n",
    "                    temp = median_filter(temp, size=self.median_filter_kernel_size, mode='nearest')\n",
    "                if self.butterworth_filters is not None and channel in self.butterworth_filters:\n",
    "                    freq_range = self.butterworth_filters[channel]\n",
    "                    btype = 'highpass' if freq_range[0] is None else 'lowpass' if freq_range[1] is None else 'bandpass'\n",
    "                    freq_range = freq_range[1] if freq_range[0] is None else freq_range[0] if freq_range[1] is None else freq_range\n",
    "                    temp = butterworth(temp, freq_range=freq_range, btype=btype, fs=channel_frequency, order=2)\n",
    "                temp = F_audio.resample(torch.from_numpy(temp), channel_frequency, self.frequency).numpy()\n",
    "            else:\n",
    "                if self.median_filter_kernel_size is not None:\n",
    "                    temp = median_filter(temp, size=self.median_filter_kernel_size, mode='nearest')\n",
    "                if self.butterworth_filters is not None and channel in self.butterworth_filters:\n",
    "                    freq_range = self.butterworth_filters[channel]\n",
    "                    btype = 'highpass' if freq_range[0] is None else 'lowpass' if freq_range[1] is None else 'bandpass'\n",
    "                    freq_range = freq_range[1] if freq_range[0] is None else freq_range[0] if freq_range[1] is None else freq_range\n",
    "                    temp = butterworth(temp, freq_range=freq_range, btype=btype, fs=self.frequency, order=2)\n",
    "            if channel in self.voltage_channels:\n",
    "                if channel_dimension.lower() == 'mv':\n",
    "                    temp = temp * 1e3\n",
    "            if self.clip_interpolations is not None and channel in self.clip_interpolations:\n",
    "                temp = interpolate_nan_clip(temp, physiological_range_clip=self.clip_interpolations[channel]['phys_range'], percentile_clip=self.clip_interpolations[channel]['percentiles'])\n",
    "            if not self.scale_channels:\n",
    "                signals.append(temp)\n",
    "            else:\n",
    "                signals.append((temp - self.time_channel_scales[channel]['mean'])/self.time_channel_scales[channel]['std'])\n",
    "        X = Y = torch.from_numpy(np.stack(signals, dtype=np.float32))\n",
    "        if self.trim_wake_epochs and 'hypnogram' in root_grp.array_keys():\n",
    "            if self.hypnogram_frequency == self.frequency:\n",
    "                # hypnogram has already been resampled\n",
    "                hypnogram = torch.from_numpy(np.array(root_grp['hypnogram'][sample['start_idx']:sample['end_idx']], dtype=np.int64))\n",
    "            else:\n",
    "                # hypnogram has sampling rate of something else\n",
    "                hyp_start_idx = int((sample['start_idx'] / self.frequency) * self.hypnogram_frequency)\n",
    "                hyp_end_idx = int((sample['end_idx'] / self.frequency) * self.hypnogram_frequency)\n",
    "                hypnogram = np.array(root_grp['hypnogram'][hyp_start_idx:hyp_end_idx], dtype=np.int64)\n",
    "                hypnogram = torch.from_numpy(hypnogram)\n",
    "        \n",
    "            expected_hyp_len = int((self.sample_seq_len / self.frequency) * self.hypnogram_frequency)\n",
    "            if hypnogram.shape[-1] < expected_hyp_len:\n",
    "                hypnogram = F.pad(hypnogram, (0, expected_hyp_len - hypnogram.shape[-1]), 'constant', value=self.hypnogram_padding_mask)\n",
    "            \n",
    "            samples_per_epoch = int(self.return_hypnogram_every_sec * self.hypnogram_frequency)\n",
    "            hypnogram = hypnogram[::samples_per_epoch]\n",
    "            hypnogram[hypnogram>5] = self.hypnogram_padding_mask # replace values > 5 with -100 (there are 8 (6 and 9 are unknown and wake, stage 4 is also present, REM is 5) classes total in shhs and they encode movement/wake as 9 and 0 as wake, this combines the two)\n",
    "        \n",
    "        sequence_padding_mask = torch.zeros([1,X.shape[-1]])\n",
    "        if X.shape[-1] < self.sample_seq_len:\n",
    "            sequence_padding_mask = F.pad(sequence_padding_mask, (0,self.sample_seq_len - sequence_padding_mask.shape[-1]), 'constant', value=1) # constant pad with 1\n",
    "            X = Y = F.pad(X, (0,self.sample_seq_len - X.shape[-1]), 'constant', value=0) # replicate pad\n",
    "        \n",
    "        # check if wake is the largest class and assign padding mask to wake epochs if so\n",
    "        if self.trim_wake_epochs and 'hypnogram' in root_grp.array_keys():\n",
    "            resampled_hypnogram_length = int(self.return_hypnogram_every_sec * self.frequency)\n",
    "            hypnogram = trim_wake_epochs_from_hypnogram(hypnogram, padding_mask=self.hypnogram_padding_mask)\n",
    "            X, sequence_padding_mask = trim_wake_epochs_from_signals(X, hypnogram=hypnogram, sequence_padding_mask=sequence_padding_mask, resampled_hypnogram_length=resampled_hypnogram_length, mask_x_with_zeros=False, padding_mask=self.hypnogram_padding_mask)\n",
    "            X = Y\n",
    "        if torch.isnan(X).any():\n",
    "            warnings.warn(f\"X has nan values, sample_idx: {idx}\")\n",
    "        if self.return_sequence_padding_mask:\n",
    "            return X, Y, sequence_padding_mask\n",
    "        else:\n",
    "            return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sleep Stage Supervised Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HypnogramTimeFrequencyDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 zarr_files, # zarr files that include samples\n",
    "                 channels, # channels to use\n",
    "                 max_seq_len_sec, # maximum sequence length (in seconds) to use (this is especially relevant when you are returning both stft and raw ts data to keep them in sync)\n",
    "                 sample_seq_len_sec, # if no sample_df, generate sequences of this length in seconds as one sample\n",
    "                 sample_stride_sec, #  if no sample_df, seconds of overlap for samples from the same array, if seq_len_seconds == overlap_seconds, there is no overlap\n",
    "                 start_offset_sec=0, # number of seconds to exclude from beginning of sleep studies\n",
    "                 trim_wake_epochs=True, # indicator to trim wake epochs from hypnograms, if it is the largest class\n",
    "                 include_partial_samples=True, # indicator to include data from partial samples when return_full_length is false\n",
    "                 sample_df=None, # dataframe indicating which indices within each zarr file includes a sample\n",
    "                 frequency=125, # frequency of underlying data\n",
    "                 return_y_every_sec=30, # integer value indicating the step in indexing in seconds\n",
    "                 y_padding_mask=-100, # padded value to add to target and indice to ignore when computing loss\n",
    "                 y_frequency=125, # frequency of underlying y hypnogram data\n",
    "                 butterworth_filters=None, # dictionary of low pass, high pass, and bandpass dictionary to perform on channels\n",
    "                 median_filter_kernel_size=None, # if not none, will apply median filter with kernel size\n",
    "                 voltage_channels=VOLTAGE_CHANNELS, # if not None, these channels units will be looked at and changed to microvolts from mv uv etc.\n",
    "                 clip_interpolations=None, # dictionary of channels:{'phys_range':..., 'percentiles':...} for filtering and interpolation of filtered values\n",
    "                 scale_channels=False, # indicator to scale channels to the mean and std of the zarr files. \n",
    "                 time_channel_scales=None, # dictionary of channel:mean and channel:std values for scaling. Should use training statistics \n",
    "                 return_sequence_padding_mask=False, # indicator to return the key padding mask for attention masking\n",
    "                 ):\n",
    "        self.max_seq_len = max_seq_len_sec*frequency\n",
    "        self.max_seq_len_sec = max_seq_len_sec\n",
    "        self.include_partial_samples = include_partial_samples\n",
    "        self.zarr_files = zarr_files\n",
    "        self.channels = channels\n",
    "        self.channels_has_dim = any(isinstance(i, list) for i in self.channels)\n",
    "        self.sample_seq_len_sec = sample_seq_len_sec\n",
    "        self.sample_seq_len = sample_seq_len_sec * frequency\n",
    "        self.frequency = frequency\n",
    "        self.sample_stride_sec = sample_stride_sec\n",
    "        self.scale_channels = scale_channels\n",
    "        self.clip_interpolations = clip_interpolations\n",
    "        self.return_y_every_sec = return_y_every_sec\n",
    "        self.y_padding_mask = y_padding_mask\n",
    "        self.y_frequency = y_frequency\n",
    "        self.return_sequence_padding_mask = return_sequence_padding_mask\n",
    "        self.start_offset_sec = start_offset_sec\n",
    "        self.trim_wake_epochs = trim_wake_epochs\n",
    "\n",
    "        self.butterworth_filters = butterworth_filters\n",
    "        self.median_filter_kernel_size = median_filter_kernel_size\n",
    "        self.voltage_channels = voltage_channels\n",
    "        \n",
    "        if sample_df is None:\n",
    "            print(f\"Calculating samples with {sample_seq_len_sec} sec length and {sample_stride_sec} sec stride with {max_seq_len_sec} sec max\")\n",
    "            self.sample_df, self.total_samples = calculate_samples_mp(zarr_files, channels=channels, max_seq_len_sec=max_seq_len_sec, sample_seq_len_sec=sample_seq_len_sec, frequency=frequency, start_offset_sec=start_offset_sec, stride_sec=sample_stride_sec, include_partial_samples=include_partial_samples)\n",
    "        else:\n",
    "            assert 'file' in sample_df, \"The `sample_df` must have a column `file` with the zarr file path.\"\n",
    "            missing_in_zarrs = len(set(sample_df['file']) - set(zarr_files))\n",
    "            missing_in_df = len(set(zarr_files) - set(sample_df['file']))\n",
    "            if missing_in_zarrs > 0 or missing_in_df > 0:\n",
    "                warnings.warn(f\"There are {missing_in_zarrs} `zarr_files` not in the `sample_df` and {missing_in_df} files in the `sample_df` that arent in the `zarr_files`, they will be ignored.\")\n",
    "            sample_df = sample_df.loc[sample_df['file'].isin(zarr_files)].copy().reset_index(drop=True)\n",
    "            self.sample_df = sample_df\n",
    "            self.total_samples = len(sample_df)\n",
    "        \n",
    "        if self.scale_channels:\n",
    "            if time_channel_scales is None or time_channel_scales == {}:\n",
    "                print(f\"Calculating sample statistics for {channels}\")\n",
    "                channel_scales_df = calculate_stats_all(zarr_files=self.sample_df.file.tolist(), channels=channels, sample_wise=False, channel_magnitude_multiple=channel_magnitude_multiple)\n",
    "                self.time_channel_scales = channel_scales_df.to_dict(orient='index')\n",
    "            else:\n",
    "                self.time_channel_scales = time_channel_scales\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get full length x, idx can be a slice\n",
    "        sample = self.sample_df.iloc[idx]\n",
    "        root_grp = zarr.open(sample['file'])\n",
    "        duration_seconds = int(root_grp.attrs.asdict()['header']['Duration'])\n",
    "        signals = []\n",
    "        channels = []\n",
    "        if self.channels_has_dim:\n",
    "            avail_channels = list(root_grp.array_keys())\n",
    "            for p in self.channels:\n",
    "                channels.append(next(x for x in p if x in avail_channels))\n",
    "        else:\n",
    "            channels = self.channels\n",
    "        for channel in channels:\n",
    "            channel_frequency = root_grp[channel].attrs.asdict()['signal_header']['sample_frequency']\n",
    "            channel_dimension = root_grp[channel].attrs.asdict()['signal_header']['dimension'] # whether in mV, microv or v\n",
    "            if channel_frequency != self.frequency:\n",
    "                start_idx, end_idx = int(sample['start_idx'] / self.frequency * channel_frequency), int(sample['end_idx'] / self.frequency * channel_frequency)\n",
    "            else:\n",
    "                start_idx, end_idx = sample['start_idx'], sample['end_idx']\n",
    "            temp = np.array(root_grp[channel][start_idx:end_idx], dtype=np.float32)\n",
    "            if channel_frequency < self.frequency:\n",
    "                # need to upsample first, then apply filters\n",
    "                #temp = resample(root_grp[channel][start_idx:end_idx], self.frequency*self.sample_seq_len_sec) if duration_seconds >= self.sample_seq_len_sec else resample(root_grp[channel][start_idx:end_idx], duration_seconds*self.frequency)\n",
    "                temp = F_audio.resample(torch.from_numpy(temp), channel_frequency, self.frequency).numpy()\n",
    "                if self.median_filter_kernel_size is not None:\n",
    "                    temp = median_filter(temp, size=self.median_filter_kernel_size, mode='nearest')\n",
    "                if self.butterworth_filters is not None and channel in self.butterworth_filters:\n",
    "                    freq_range = self.butterworth_filters[channel]\n",
    "                    btype = 'highpass' if freq_range[0] is None else 'lowpass' if freq_range[1] is None else 'bandpass'\n",
    "                    freq_range = freq_range[1] if freq_range[0] is None else freq_range[0] if freq_range[1] is None else freq_range\n",
    "                    temp = butterworth(temp, freq_range=freq_range, btype=btype, fs=self.frequency, order=2)\n",
    "            elif channel_frequency > self.frequency:\n",
    "                # need to upsample or downsample, filter first, then resample\n",
    "                if self.median_filter_kernel_size is not None:\n",
    "                    temp = median_filter(temp, size=self.median_filter_kernel_size, mode='nearest')\n",
    "                if self.butterworth_filters is not None and channel in self.butterworth_filters:\n",
    "                    freq_range = self.butterworth_filters[channel]\n",
    "                    btype = 'highpass' if freq_range[0] is None else 'lowpass' if freq_range[1] is None else 'bandpass'\n",
    "                    freq_range = freq_range[1] if freq_range[0] is None else freq_range[0] if freq_range[1] is None else freq_range\n",
    "                    temp = butterworth(temp, freq_range=freq_range, btype=btype, fs=channel_frequency, order=2)\n",
    "                temp = F_audio.resample(torch.from_numpy(temp), channel_frequency, self.frequency).numpy()\n",
    "            else:\n",
    "                if self.median_filter_kernel_size is not None:\n",
    "                    temp = median_filter(temp, size=self.median_filter_kernel_size, mode='nearest')\n",
    "                if self.butterworth_filters is not None and channel in self.butterworth_filters:\n",
    "                    freq_range = self.butterworth_filters[channel]\n",
    "                    btype = 'highpass' if freq_range[0] is None else 'lowpass' if freq_range[1] is None else 'bandpass'\n",
    "                    freq_range = freq_range[1] if freq_range[0] is None else freq_range[0] if freq_range[1] is None else freq_range\n",
    "                    temp = butterworth(temp, freq_range=freq_range, btype=btype, fs=self.frequency, order=2)\n",
    "            if channel in self.voltage_channels:\n",
    "                if channel_dimension.lower() == 'mv':\n",
    "                    temp = temp * 1e3\n",
    "            if self.clip_interpolations is not None and channel in self.clip_interpolations:\n",
    "                temp = interpolate_nan_clip(temp, physiological_range_clip=self.clip_interpolations[channel]['phys_range'], percentile_clip=self.clip_interpolations[channel]['percentiles'])\n",
    "            if not self.scale_channels:\n",
    "                signals.append(temp)\n",
    "            else:\n",
    "                signals.append((temp - self.time_channel_scales[channel]['mean'])/self.time_channel_scales[channel]['std'])\n",
    "        X = torch.from_numpy(np.stack(signals, dtype=np.float32))\n",
    "        if self.y_frequency == self.frequency:\n",
    "            # hypnogram has already been resampled\n",
    "            Y = torch.from_numpy(np.array(root_grp['hypnogram'][sample['start_idx']:sample['end_idx']], dtype=np.int64))\n",
    "        else:\n",
    "            # hypnogram has sampling rate of something else\n",
    "            hyp_start_idx = int((sample['start_idx'] / self.frequency) * self.y_frequency)\n",
    "            hyp_end_idx = int((sample['end_idx'] / self.frequency) * self.y_frequency)\n",
    "            Y = np.array(root_grp['hypnogram'][hyp_start_idx:hyp_end_idx], dtype=np.int64)\n",
    "            Y = torch.from_numpy(Y)\n",
    "        \n",
    "        sequence_padding_mask = torch.zeros([1,X.shape[-1]])\n",
    "        if X.shape[-1] < self.sample_seq_len:\n",
    "            sequence_padding_mask = F.pad(sequence_padding_mask, (0,self.sample_seq_len - sequence_padding_mask.shape[-1]), 'constant', value=1) # constant pad with 1\n",
    "            X = F.pad(X, (0,self.sample_seq_len - X.shape[-1]), 'constant', value=0) # replicate pad\n",
    "        \n",
    "        expected_hyp_len = int((self.sample_seq_len / self.frequency) * self.y_frequency)\n",
    "        if Y.shape[-1] < expected_hyp_len:\n",
    "            Y = F.pad(Y, (0, expected_hyp_len - Y.shape[-1]), 'constant', value=self.y_padding_mask)\n",
    "        \n",
    "        samples_per_epoch = int(self.return_y_every_sec * self.y_frequency)\n",
    "        Y = Y[::samples_per_epoch]\n",
    "\n",
    "        assert Y.max() <= 4 and (Y.min() == self.y_padding_mask or Y.min() >= 0), \"There are values greater than 4 in the hypnogram or less than 0 that are not the padding mask. This is unexpected. 0-4 are the only valid values indicating wake, n1, n2, n3, rem, and a padding mask.\"\n",
    "        # check if wake is the largest class and assign padding mask to wake epochs if so\n",
    "        if self.trim_wake_epochs:\n",
    "            resampled_hypnogram_length = int(self.return_y_every_sec * self.frequency)\n",
    "            Y = trim_wake_epochs_from_hypnogram(Y, padding_mask=self.y_padding_mask)\n",
    "            X, sequence_padding_mask = trim_wake_epochs_from_signals(X, hypnogram=Y, sequence_padding_mask=sequence_padding_mask, resampled_hypnogram_length=resampled_hypnogram_length, mask_x_with_zeros=False, padding_mask=self.y_padding_mask)\n",
    "        if torch.isnan(X).any():\n",
    "            warnings.warn(f\"X has nan values, sample_idx: {idx}\")\n",
    "        if torch.isnan(Y).any():\n",
    "            warnings.warn(f\"Y has nan values, sample_idx: {idx}\")\n",
    "        if self.return_sequence_padding_mask:\n",
    "            return X, Y, sequence_padding_mask\n",
    "        else:\n",
    "            return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_edf_signals(signals, signal_names, signal_comparisons=None, use_resampler=False, normalize=False, title_text='', colorscale=None):\n",
    "    fig = go.Figure().set_subplots(len(signal_names), 1, shared_xaxes=True, vertical_spacing=0.01)\n",
    "    if use_resampler:\n",
    "        fig = FigureWidgetResampler(fig)\n",
    "    n_colors = len(signals)\n",
    "    if colorscale is not None:\n",
    "        colors = px.colors.sample_colorscale(colorscale, [n/(n_colors-1) if n_colors != 1 else 0 for n in range(n_colors)])\n",
    "    else:\n",
    "        colors = ['#1F77B4', '#FF7F0E', '#2CA02C', '#D62728', '#9467BD', '#8C564B', '#E377C2']\n",
    "    for idx, s in enumerate(signals):\n",
    "        y = (s - s.min())/(s.max() - s.min()) if normalize else s\n",
    "        fig.add_trace(go.Scattergl(name=signal_names[idx],  \n",
    "                                    mode='markers+lines', \n",
    "                                    marker_opacity=0, line={'width': 1.5, 'color':colors[idx]},\n",
    "                                    y=y),\n",
    "                                    row=idx+1,\n",
    "                                    col=1\n",
    "                                    )\n",
    "    if signal_comparisons is not None:\n",
    "        for idx, s in enumerate(signal_comparisons):\n",
    "            y = (s - s.min())/(s.max() - s.min()) if normalize else s\n",
    "            fig.add_trace(go.Scattergl(name=None,#signal_names[idx],  \n",
    "                                        mode='markers+lines', \n",
    "                                        showlegend=False,\n",
    "                                        marker_opacity=0, line={'width': 1.5, 'color':'black'},\n",
    "                                        y=y),\n",
    "                                        row=idx+1,\n",
    "                                        col=1\n",
    "                                        )\n",
    "    fig.update_layout(height=800, width=1500, \n",
    "                      title_text=f\"{title_text}\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
