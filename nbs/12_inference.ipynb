{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891d6ac9",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4ec2c",
   "metadata": {},
   "source": [
    "> For you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a27d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7da50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12833478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pftsleep/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import os, torch, numpy as np, warnings, edfio, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pftsleep.train import PatchTFTSleepStage, PatchTFTSimpleLightning\n",
    "from pftsleep.heads import RNNProbingHeadExperimental\n",
    "\n",
    "from scipy.signal import resample\n",
    "from huggingface_hub import hf_hub_download\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "from pftsleep.signal import butterworth\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "ENCODER_DEFAULTS = dict(c_in=7,\n",
    "            win_length=750,\n",
    "            hop_length=750,\n",
    "            max_seq_len=8*3600*125,\n",
    "            use_revin=True,\n",
    "            dim1reduce = False,\n",
    "            use_flash_attn=False, \n",
    "            affine=True, # need to test with both true and false\n",
    "            augmentations=['jitter_zero_mask'],#jitter_zero_mask', 'reverse_sequence', 'shuffle_channels'],\n",
    "            mask_ratio=0.1,\n",
    "            n_layers=3,\n",
    "            d_model=512,\n",
    "            n_heads=4,\n",
    "            shared_embedding=False,\n",
    "            d_ff=2048,\n",
    "            norm='BatchNorm',\n",
    "            attn_dropout=0.,\n",
    "            dropout=0.1,\n",
    "            act=\"gelu\", \n",
    "            res_attention=True,\n",
    "            pre_norm=False,\n",
    "            store_attn=False,\n",
    "            pretrain_head=True,\n",
    "            pretrain_head_n_layers=1,\n",
    "            pretrain_head_dropout=0.\n",
    "            )\n",
    "\n",
    "CLASSIFIER_HEAD_DEFAULTS = dict(c_in=7, \n",
    "                input_size=512,\n",
    "                hidden_size=1024,\n",
    "                predict_every_n_patches=5, \n",
    "                n_classes=5, \n",
    "                num_rnn_layers=2,\n",
    "                contrastive=False,\n",
    "                rnn_dropout=0.1, \n",
    "                module='GRU',\n",
    "                bidirectional=True,\n",
    "                affine=True,\n",
    "                pool='average', \n",
    "                pre_norm=False, \n",
    "                mlp_final_head=True,\n",
    "                linear_dropout=0.1,\n",
    "                temperature=2)\n",
    "\n",
    "FREQUENCY_DEFAULT = 125\n",
    "HYPNOGRAM_FREQUENCY_DEFAULT = 1\n",
    "HYPNOGRAM_EPOCH_SECONDS_DEFAULT = 30\n",
    "SEQUENCE_LENGTH_SECONDS_DEFAULT = (8*3600) # 8 hrs\n",
    "HYPNOGRAM_PADDING_DEFAULT = -100\n",
    "\n",
    "\n",
    "FREQUENCY_FILTERS_ORDERED_DEFAULT = [[0.5,40], # ECG\n",
    "            [0.3,30], # EOG L\n",
    "            [0.3,30], # Chin EMG\n",
    "            [0.3,30], # EEG\n",
    "            [0.4, None], # SpO2\n",
    "            [0.5, None], # Thoracic RR\n",
    "            [0.5, None], # Abdominal RR\n",
    "            ]\n",
    "\n",
    "MEDIAN_FILTER_KERNEL_SIZE_DEFAULT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdcc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_pftsleep_models(models_dir='', # The directory of the saved models\n",
    "                         encoder_model_name='pft_sleep_encoder.ckpt', # the name of the encoder model\n",
    "                         classifier_model_name='pft_sleep_classifier.ckpt', # the name of the classifier model\n",
    "                         classifier_head_defaults=CLASSIFIER_HEAD_DEFAULTS, # the defaults for the classifier head, DO NOT CHANGE!\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    Loads the pftsleep models from the models directory\n",
    "\n",
    "    Args:\n",
    "        models_dir (str): The directory of the saved models\n",
    "        encoder_model_name (str): The name of the encoder model\n",
    "        classifier_model_name (str): The name of the classifier model\n",
    "        classifier_head_defaults (dict): The defaults for the classifier head, DO NOT CHANGE!\n",
    "    Returns:\n",
    "        encoder (PatchTFTSimpleLightning): The encoder model\n",
    "        ss_classifier (PatchTFTSleepStage): The classifier model\n",
    "    \"\"\"\n",
    "    encoder = PatchTFTSimpleLightning.load_from_checkpoint(os.path.join(models_dir, encoder_model_name), map_location='cpu')\n",
    "    lp_model = RNNProbingHeadExperimental(**classifier_head_defaults)\n",
    "    ss_classifier = PatchTFTSleepStage.load_from_checkpoint(os.path.join(models_dir, classifier_model_name),\n",
    "                                                            preloaded_model=encoder,\n",
    "                                                            map_location='cpu',\n",
    "                                                            linear_probing_head = lp_model\n",
    "                                                        )\n",
    "    return encoder, ss_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b8ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_pftsleep_models(write_dir='', # The directory to write the models to\n",
    "                             token=None # Your hugging face token to use to download the models\n",
    "                             ):\n",
    "    \"\"\"\n",
    "    Function to download pftsleep models from hugging face\n",
    "\n",
    "    Args:\n",
    "        write_dir (str): The directory to write the models to\n",
    "        token (str): Your hugging face token to use to download the models\n",
    "    \"\"\"\n",
    "    hf_hub_download(repo_id=\"benmfox/PFTSleep\", local_dir=write_dir, filename=\"pft_sleep_encoder.ckpt\", token=token)\n",
    "    hf_hub_download(repo_id=\"benmfox/PFTSleep\", local_dir=write_dir, filename=\"pft_sleep_classifier.ckpt\", token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_edf(edf_file_path, # The edf file path to perform inference on\n",
    "                channels, # the channels to read from the edf file\n",
    "                reference_channels_dict={}, # the reference channels to subtract from the channels. The keys are the channels to subtract from, and the values are the reference channels.\n",
    "                frequency=FREQUENCY_DEFAULT, # the frequency to resample the channels to. Do not change this!\n",
    "                sample_length=SEQUENCE_LENGTH_SECONDS_DEFAULT, # the length of the sequence to pad the channels to, expected by the model. Do not change this!\n",
    "                frequency_filters_ordered=FREQUENCY_FILTERS_ORDERED_DEFAULT, # the frequency filters to apply to the channels. Do not change this!\n",
    "                median_filter_kernel_size=3, # the kernel size for the median filter. Do not change this!\n",
    "                overwrite_edf_duration=False, # whether to overwrite the duration of the edf file to the sample length, if the edf file duration key is corrupted. \n",
    "                verbose=True, # whether to print the verbose output.\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Process the edf file to prepare it for inference. \n",
    "    This function is used to prepare the edf file for inference by reading the channels, resampling them to the correct frequency, filtering them, and padding them to the correct length.\n",
    "    Do not change the default parameters (frequency, sample_length, frequency_filters_ordered, median_filter_kernel_size) of this function!\n",
    "\n",
    "    Args:\n",
    "        edf_file_path (str): The path to the edf file to perform inference on\n",
    "        channels (list): The channels to read from the edf file\n",
    "        reference_channels_dict (dict): The reference channels to subtract from the channels. The keys are the channels to subtract from, and the values are the reference channels.\n",
    "        frequency (int): The frequency to resample the channels to. Do not change this!\n",
    "        sample_length (int): The length of the sequence to pad the channels to, expected by the model. Do not change this!\n",
    "        frequency_filters_ordered (list): The frequency filters to apply to the channels. Do not change this!\n",
    "        median_filter_kernel_size (int): The kernel size for the median filter. Do not change this!\n",
    "        overwrite_edf_duration (bool): Whether to overwrite the duration of the edf file to the sample length, if the edf file duration key is corrupted. \n",
    "        verbose (bool): Whether to print the verbose output.\n",
    "\n",
    "    Returns:\n",
    "        signals (torch.Tensor): The processed signals\n",
    "        sequence_padding_mask (torch.Tensor): The sequence padding mask\n",
    "    \"\"\"\n",
    "    assert set(reference_channels_dict.keys()).issubset(set(channels)), 'The reference channels must be a subset of the channels'\n",
    "    assert len(channels) == len(frequency_filters_ordered), 'The number of channels and the number of frequency filters must be the same'\n",
    "    if sample_length != SEQUENCE_LENGTH_SECONDS_DEFAULT:\n",
    "        warnings.warn(f'Sample length is not set to the default of {SEQUENCE_LENGTH_SECONDS_DEFAULT} seconds. This will likely cause issues with the model.')\n",
    "    if frequency != FREQUENCY_DEFAULT:\n",
    "        warnings.warn(f'Frequency is not set to the default of {FREQUENCY_DEFAULT} Hz. This will likely cause issues with the model.')\n",
    "    f = edfio.read_edf(edf_file_path, lazy_load_data=True)\n",
    "    num_channels = f.num_signals\n",
    "    available_channels = [channel.upper() for channel in f.labels]\n",
    "    channels_all = [channel.upper() for channel in channels]\n",
    "    channels = [channel.upper() for channel in channels if channel.lower() != 'dummy']\n",
    "    if len(set(channels) - set(available_channels)) != 0:\n",
    "        raise ValueError(f'Missing channels in edf file: {set(channels) - set(available_channels)}')\n",
    "    channels_to_get = list(set(channels) & set(available_channels))\n",
    "    channels_idxs = [available_channels.index(c) for c in channels_to_get]\n",
    "    if reference_channels_dict:\n",
    "        reference_channels = [channel.upper() for channel in reference_channels_dict.values() if channel is not None]\n",
    "        if len(set(reference_channels) - set(available_channels)) != 0:\n",
    "            raise ValueError(f'Missing reference channels in edf file: {set(reference_channels) - set(available_channels)}')\n",
    "        reference_channels_to_get = list(set(reference_channels) & set(available_channels))\n",
    "        reference_channels_idxs = [available_channels.index(c) for c in reference_channels_to_get]\n",
    "    if overwrite_edf_duration:\n",
    "        duration = sample_length\n",
    "    else:\n",
    "        duration = int(f.duration)\n",
    "    if duration < sample_length / 2:\n",
    "        warnings.warn(f'Duration of edf file is less than half of the expected (~ 8 Hrs) sample length: {duration} < {sample_length / 2}')\n",
    "    signal_headers = [{'label':f.signals[i].label, \n",
    "                        'dimension':f.signals[i].physical_dimension,\n",
    "                        'sample_rate':f.signals[i].sampling_frequency if frequency is None else frequency,\n",
    "                        'sample_frequency':f.signals[i].sampling_frequency if frequency is None else frequency,\n",
    "                        'physical_max': f.signals[i].physical_max,\n",
    "                        'physical_min': f.signals[i].physical_min,\n",
    "                        'digital_max': f.signals[i].digital_max,\n",
    "                        'digital_min': f.signals[i].digital_min,\n",
    "                        'prefilter': f.signals[i].prefiltering,\n",
    "                        'transducer': f.signals[i].transducer_type} for i in channels_idxs]\n",
    "    if verbose:\n",
    "        print(f'EDF file: {edf_file_path}')\n",
    "        print(f'Duration: {duration}')\n",
    "        print(f'Number of channels: {num_channels}')\n",
    "        print(f'Available channels: {available_channels}')\n",
    "        print(f'Signal headers: {signal_headers}')\n",
    "    signals = []\n",
    "    required_length = duration * int(frequency)\n",
    "    for c_idx, channel_name in zip(channels_idxs, channels):\n",
    "        signal = f.signals[c_idx].data\n",
    "        if reference_channels_dict and channel_name in reference_channels_dict and len(reference_channels_idxs) > 0:\n",
    "            reference_signal = f.signals[reference_channels_idxs[reference_channels.index(channel_name)]].data\n",
    "            signal = signal - reference_signal\n",
    "        if len(signal) != required_length:\n",
    "            signal = resample(signal, required_length)\n",
    "        signals.append(signal)\n",
    "    channel_order = [i['label'].upper() for i in signal_headers if i['label'].upper() in channels] # get channel order of signals\n",
    "    signals = np.array(signals, dtype=np.float32)\n",
    "    signals = signals[[channel_order.index(c) for c in channels]]\n",
    "    filtered_signals = []\n",
    "    for s, freq_range in zip(signals, frequency_filters_ordered):\n",
    "        if median_filter_kernel_size is not None:\n",
    "            s = median_filter(s, size=median_filter_kernel_size, mode='nearest')\n",
    "        btype = 'highpass' if freq_range[0] is None else 'lowpass' if freq_range[1] is None else 'bandpass'\n",
    "        freq_range = freq_range[1] if freq_range[0] is None else freq_range[0] if freq_range[1] is None else freq_range\n",
    "        s = butterworth(s, freq_range=freq_range, btype=btype, fs=frequency, order=2)\n",
    "        filtered_signals.append(s)\n",
    "    dummy_idxs = [i for i, c in enumerate(channels_all) if c.lower() == 'dummy']\n",
    "    for i in dummy_idxs:\n",
    "        filtered_signals.insert(i, np.zeros(len(filtered_signals[0])))\n",
    "    assert signals.shape[0] == len(channels), f\"Signals shape is not equal to the number of channels: {signals.shape[0]} != {len(channels)}\"\n",
    "    signals = torch.from_numpy(np.array(filtered_signals, dtype=np.float32))\n",
    "    sample_length_idx = int(sample_length * frequency)\n",
    "    signals = signals[:sample_length_idx]\n",
    "    sequence_padding_mask = torch.zeros([signals.shape[-1]])\n",
    "    if duration < sample_length:\n",
    "        if signals.shape[-1] < sample_length_idx:\n",
    "            sequence_padding_mask = F.pad(sequence_padding_mask, (0, sample_length_idx - sequence_padding_mask.shape[-1]), 'constant', value=1) # constant pad with 1\n",
    "            signals = F.pad(signals, (0, sample_length_idx - signals.shape[-1]), 'constant', value=0) # replicate pad\n",
    "    return signals, sequence_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff630e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def view_edf_channels(edf_file_path, # The path to the edf file to view the channels of\n",
    "                      uppercase=True # Whether to return the channels in uppercase\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    View the channels of an edf file.\n",
    "\n",
    "    Args:\n",
    "        edf_file_path (str): The path to the edf file to view the channels of\n",
    "        uppercase (bool): Whether to return the channels in uppercase\n",
    "\n",
    "    Returns:\n",
    "        channels (list): The channels in the edf file\n",
    "    \"\"\"\n",
    "    f = edfio.read_edf(edf_file_path, lazy_load_data=True)\n",
    "    if uppercase:\n",
    "        return [channel.upper() for channel in f.labels]\n",
    "    else:\n",
    "        return f.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fba004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class EDFDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                edf_file_paths, # The paths to the edf files to perform inference on\n",
    "                eeg_channel, # the EEG channel name in the EDF. The model was trained with C4-M1 and C3-M2 referenced EEG channels. However, \n",
    "                left_eog_channel, # the left EOG channel name in the EDF. The model was trained with M2 referenced left EOG channels.\n",
    "                chin_emg_channel, # the chin EMG channel name in the EDF. The model was trained with chin refenced (chin 2 or chin 3) EMG channels.\n",
    "                ecg_channel, # the ECG channel name in the EDF. The model was trained with augmented lead 2 ecg channels\n",
    "                spo2_channel, # the SpO2 channel name in the EDF.\n",
    "                abdomen_rr_channel, # the abdomen RR channel name in the EDF. \n",
    "                thoracic_rr_channel, # the thoracic RR channel name in the EDF.\n",
    "                eeg_reference_channel=None, # the EEG reference channel name in the EDF. The model was trained with C4-M1 and C3-M2 referenced EEG channels. This will reference the channels, if they havent already been referenced. \n",
    "                left_eog_reference_channel=None, # the left EOG reference channel name in the EDF. The model was trained with M2 referenced left EOG channels. This will reference the channels, if they havent already been referenced. \n",
    "                chin_emg_reference_channel=None, # the chin EMG reference channel name in the EDF. The model was trained with chin refenced (chin 2 or chin 3) EMG channels. This will reference the channels, if they havent already been referenced. \n",
    "                ecg_reference_channel=None, # the ECG reference channel name in the EDF. The model was trained with augmented lead 2 ecg channels. This will reference the channels, if they havent already been referenced. \n",
    "                **kwargs\n",
    "                ):\n",
    "        \"\"\"\n",
    "        A dataset class for performing inference on multiple edf files.\n",
    "\n",
    "        Args:\n",
    "            edf_file_paths (list): The paths to the edf files to perform inference on\n",
    "            eeg_channel (str): The name of the EEG channel in the EDF\n",
    "            left_eog_channel (str): The name of the left EOG channel in the EDF\n",
    "            chin_emg_channel (str): The name of the chin EMG channel in the EDF\n",
    "            ecg_channel (str): The name of the ECG channel in the EDF\n",
    "            spo2_channel (str): The name of the SpO2 channel in the EDF\n",
    "            abdomen_rr_channel (str): The name of the abdomen RR channel in the EDF\n",
    "            thoracic_rr_channel (str): The name of the thoracic RR channel in the EDF\n",
    "            eeg_reference_channel (str): The name of the EEG reference channel in the EDF\n",
    "            left_eog_reference_channel (str): The name of the left EOG reference channel in the EDF\n",
    "            chin_emg_reference_channel (str): The name of the chin EMG reference channel in the EDF\n",
    "            ecg_reference_channel (str): The name of the ECG reference channel in the EDF\n",
    "            **kwargs: Additional keyword arguments for process_edf function\n",
    "        \"\"\"\n",
    "        self.edf_file_paths = edf_file_paths\n",
    "        self.channels = [ecg_channel, left_eog_channel, chin_emg_channel, eeg_channel, spo2_channel, thoracic_rr_channel, abdomen_rr_channel]\n",
    "        self.channels = [c if c is not None and c != 'dummy' else 'dummy' for c in self.channels]\n",
    "        self.reference_channels_dict = {ecg_channel: ecg_reference_channel,\n",
    "                                        left_eog_channel: left_eog_reference_channel,\n",
    "                                        chin_emg_channel: chin_emg_reference_channel,\n",
    "                                        eeg_channel: eeg_reference_channel}\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.edf_file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signals, sequence_padding_mask = process_edf(self.edf_file_paths[idx],\n",
    "                    channels=self.channels,\n",
    "                    reference_channels_dict=self.reference_channels_dict,\n",
    "                    verbose=False,\n",
    "                    **self.kwargs)\n",
    "        return signals, sequence_padding_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960bbbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def map_stage(stage):\n",
    "    if stage == 4:\n",
    "        return 5  # REM\n",
    "    elif stage in (0, 1, 2, 3):\n",
    "        return stage\n",
    "    else:\n",
    "        return -1  # Undefined\n",
    " \n",
    "def create_hypjson(epochs):\n",
    "    return {\n",
    "        \"header\": {\n",
    "            \"study_date\": \"\",\n",
    "            \"study_time\": \"\",\n",
    "            \"study_id\": \"\",\n",
    "            \"version\": \"6.0.1.24\"\n",
    "        },\n",
    "        \"Data\": {\n",
    "            \"10sEpochs\": epochs\n",
    "        },\n",
    "        \"Legend\": {\n",
    "            \"undefined\": -1,\n",
    "            \"awake\": 0,\n",
    "            \"stage1\": 1,\n",
    "            \"stage2\": 2,\n",
    "            \"stage3\": 3,\n",
    "            \"stage4\": 4,\n",
    "            \"REM\": 5\n",
    "        }\n",
    "    }\n",
    "\n",
    "def write_pred_to_hypjson(predictions, hypjson_path):\n",
    "    \"\"\"\n",
    "    Function to write the predictions to a hypjson file.\n",
    "    \"\"\"\n",
    "    out = torch.softmax(predictions, dim=0) # apply softmax to get probabilities\n",
    "    out = out.argmax(0).cpu().numpy().astype(int).repeat(3) # repeat each epoch 3 times to get 10s epochs from 30s epochs\n",
    "    hypjson_epochs = list(map(map_stage, out.tolist())) # map stages\n",
    "    hyp_json = create_hypjson(hypjson_epochs)\n",
    "    with open(hypjson_path, 'w') as out_file:\n",
    "        json.dump(hyp_json, out_file, indent=4)\n",
    "    print(f'Saved hypjson file to {hypjson_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def infer_on_edf(edf_file_path, # The edf file path to perform inference on\n",
    "                eeg_channel, # the EEG channel name in the EDF. The model was trained with C4-M1 and C3-M2 referenced EEG channels. However, \n",
    "                left_eog_channel, # the left EOG channel name in the EDF. The model was trained with M2 referenced left EOG channels.\n",
    "                chin_emg_channel, # the chin EMG channel name in the EDF. The model was trained with chin refenced (chin 2 or chin 3) EMG channels.\n",
    "                ecg_channel, # the ECG channel name in the EDF. The model was trained with augmented lead 2 ecg channels\n",
    "                spo2_channel, # the SpO2 channel name in the EDF.\n",
    "                abdomen_rr_channel, # the abdomen RR channel name in the EDF. \n",
    "                thoracic_rr_channel, # the thoracic RR channel name in the EDF.\n",
    "                eeg_reference_channel=None, # the EEG reference channel name in the EDF. The model was trained with C4-M1 and C3-M2 referenced EEG channels. This will reference the channels, if they havent already been referenced. \n",
    "                left_eog_reference_channel=None, # the left EOG reference channel name in the EDF. The model was trained with M2 referenced left EOG channels. This will reference the channels, if they havent already been referenced. \n",
    "                chin_emg_reference_channel=None, # the chin EMG reference channel name in the EDF. The model was trained with chin refenced (chin 2 or chin 3) EMG channels. This will reference the channels, if they havent already been referenced. \n",
    "                ecg_reference_channel=None, # the ECG reference channel name in the EDF. The model was trained with augmented lead 2 ecg channels. This will reference the channels, if they havent already been referenced. \n",
    "                models_dir='', # the directory of the saved models\n",
    "                encoder_model_name='pft_sleep_encoder.ckpt', # the name of the encoder model\n",
    "                classifier_model_name='pft_sleep_classifier.ckpt', # the name of the classifier model\n",
    "                device=\"cpu\", # the device to run the model on\n",
    "                **kwargs\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Performs inference on a single edf file using the pftsleep models. \n",
    "    If you specify a channel as None or 'dummy', the channel will be passed through as a zero vector. This allows you to use the model even if some channels are not present in the edf file.\n",
    "\n",
    "    Args:\n",
    "        edf_file_path (str): The path to the edf file to perform inference on\n",
    "        eeg_channel (str): The name of the EEG channel in the EDF\n",
    "        left_eog_channel (str): The name of the left EOG channel in the EDF\n",
    "        chin_emg_channel (str): The name of the chin EMG channel in the EDF\n",
    "        ecg_channel (str): The name of the ECG channel in the EDF\n",
    "        spo2_channel (str): The name of the SpO2 channel in the EDF\n",
    "        abdomen_rr_channel (str): The name of the abdomen RR channel in the EDF\n",
    "        thoracic_rr_channel (str): The name of the thoracic RR channel in the EDF\n",
    "        eeg_reference_channel (str): The name of the EEG reference channel in the EDF\n",
    "        left_eog_reference_channel (str): The name of the left EOG reference channel in the EDF\n",
    "        chin_emg_reference_channel (str): The name of the chin EMG reference channel in the EDF\n",
    "        ecg_reference_channel (str): The name of the ECG reference channel in the EDF\n",
    "        models_dir (str): The directory of the saved models\n",
    "        encoder_model_name (str): The name of the encoder model\n",
    "        classifier_model_name (str): The name of the classifier model\n",
    "        device (str): The device to run the model on\n",
    "        **kwargs: Additional keyword arguments for process_edf function\n",
    "\n",
    "    Returns:\n",
    "        out (torch.Tensor): The sleep stage logit outputs of the classifier for each sleep epoch in the edf file\n",
    "    \"\"\"\n",
    "    if not os.path.exists(os.path.join(models_dir, encoder_model_name)):\n",
    "        raise ValueError(f\"Encoder model not found in {models_dir}\")\n",
    "    if not os.path.exists(os.path.join(models_dir, classifier_model_name)):\n",
    "        raise ValueError(f\"Classifier model not found in {models_dir}\")\n",
    "    if not os.path.exists(edf_file_path):\n",
    "        raise ValueError(f\"EDF file not found in {edf_file_path}\")\n",
    "    try:\n",
    "        _, ss_classifier = load_pftsleep_models(models_dir, encoder_model_name, classifier_model_name)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Trouble loading models: {e}\")\n",
    "    \n",
    "    try:\n",
    "        channels = [ecg_channel, left_eog_channel, chin_emg_channel, eeg_channel, spo2_channel, thoracic_rr_channel, abdomen_rr_channel]\n",
    "        channels = [c if c is not None and c != 'dummy' else 'dummy' for c in channels]\n",
    "        signals, sequence_padding_mask = process_edf(edf_file_path,\n",
    "                                                    channels=channels,\n",
    "                                                    reference_channels_dict={ecg_channel: ecg_reference_channel,\n",
    "                                                                            left_eog_channel: left_eog_reference_channel,\n",
    "                                                                            chin_emg_channel: chin_emg_reference_channel,\n",
    "                                                                            eeg_channel: eeg_reference_channel},\n",
    "                                                    **kwargs\n",
    "                                                    )\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Trouble processing edf file: {e}\")\n",
    "    \n",
    "    try:\n",
    "        # fine-tuned sleep stage classifier, recommend using a GPU\n",
    "        ss_classifier = ss_classifier.to(device)\n",
    "        ss_classifier.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            signals = signals.unsqueeze(0).to(device)\n",
    "            sequence_padding_mask = sequence_padding_mask.unsqueeze(0).to(device)\n",
    "            out = ss_classifier(signals, sequence_padding_mask=sequence_padding_mask)\n",
    "            out = out.squeeze(0).cpu()\n",
    "            # trim the output to the original signal length (if it was shorter)\n",
    "            #padding_begins = (sequence_padding_mask == 1).nonzero(as_tuple=False)[0]\n",
    "            #cutoff = int(padding_begins // (30 * FREQUENCY_DEFAULT))\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Trouble inferring on edf file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc58a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = infer_on_edf(edf_file_path=''\n",
    "#              eeg_channel='C4-M1', \n",
    "#              left_eog_channel='E1-M2', \n",
    "#              chin_emg_channel='EMG1-EMG2', \n",
    "#              ecg_channel='ECG1-ECG2', \n",
    "#              spo2_channel='SPO2', \n",
    "#              abdomen_rr_channel='ABDO', \n",
    "#              thoracic_rr_channel='dummy',\n",
    "#              device='mps',\n",
    "#              models_dir='../'\n",
    "#              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def infer_on_edf_dataset(edf_dataloader, # the edf dataset to perform inference on\n",
    "                        device='cpu', # the device to run the model on\n",
    "                        models_dir='', # the directory of the saved models\n",
    "                        encoder_model_name='pft_sleep_encoder.ckpt', # the name of the encoder model\n",
    "                        classifier_model_name='pft_sleep_classifier.ckpt', # the name of the classifier model\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    Performs inference on an EDFDataset.\n",
    "\n",
    "    Args:\n",
    "        edf_dataloader (DataLoader): The dataloader (from EDFDataset) to perform inference on\n",
    "        device (str): The device to run the model on\n",
    "        batch_size (int): The batch size to use for inference\n",
    "        models_dir (str): The directory of the saved models\n",
    "        encoder_model_name (str): The name of the encoder model\n",
    "        classifier_model_name (str): The name of the classifier model\n",
    "\n",
    "    Returns:\n",
    "        preds (list): The predicted sleep stage logits for each edf file\n",
    "    \"\"\"\n",
    "    _, ss_classifier = load_pftsleep_models(models_dir, encoder_model_name, classifier_model_name)\n",
    "    preds = []\n",
    "    ss_classifier = ss_classifier.to(device)\n",
    "    ss_classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(edf_dataloader, desc=\"Predicting\"):\n",
    "            x, sequence_padding_mask = batch\n",
    "            x = x.to(device)\n",
    "            sequence_padding_mask = sequence_padding_mask.to(device)\n",
    "            pred = ss_classifier(x, sequence_padding_mask=sequence_padding_mask) # [bs, n_classes, pred_len_seconds]\n",
    "            preds.append(pred.cpu())\n",
    "    return torch.cat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ee676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
